# Hazelcast

1. Після налаштування hazelcast

2. Запущені 3 ноди:

![img](./img/1.jpg)

ці три ноди у management center:

![img](./img/2.jpg)

3. запит клієнта на створення distributed map,

![img](./img/3.jpg)

створена distributed map, 1000 entries:

![img](./img/4.jpg)

Розподіл entries по нодах:

![img](./img/5.jpg)

Вимикаємо першу ноду:

![img](./img/6.jpg)

![img](./img/7.jpg)

Як змінився розподіл по нодах після вимкнення першої ноди:

![img](./img/8.jpg)

Вимикаємо другу ноду:

![img](./img/9.jpg)

Лишається одна:

![img](./img/10.jpg)

Розподіл entries після цього:

![img](./img/11.jpg)

Результат якщо вимикати дві ноди одночасно (програмно):

![img](./img/13.jpg)

Висновок - втрати даних не буде, якщо працює хоч одна нода, якщо треба, дані не втрачались при падінні усіх серверів, для hazelcast треба задати persistance.

4. Після роботи з distributed map, збільшення значення "key" трьома клієнтами паралельно 10000 разів, значення ключа "key"

![img](./img/14.jpg)

5. Доступ з pessimistic locks, значення ключа 30000, однак працює довго:

![img](./img/19.jpg)

Час виконання:

![img](./img/18.jpg)

6. Доступ з optimistic locks:

![img](./img/21.jpg)

Час виконання:

![img](./img/20.jpg)

7. Порівняння:

Для доступу без блокування при паралельно запущених клієнтах справді зустрічається втрата даних через race condition.

Реалізація з песимістичним блокування набагато надійніша, але в 4 рази повільніша ніж реалізація з оптимістичним блокуванням.

Песимістичне блокування краще задіювати, коли доступ до даних справді частий, очікується, що часто виникатиме конфлікт і потрібно забезпечити цілісність даних. Якщо конфлікти не очікуються часто, і latency важливіше - кращим варіантом буде optimistic locking

8. Робота із bounded queue:

![img](./img/22.jpg)

![img](./img/23.jpg)

Без consumer-а, програма просто зависає, бо черга обмежена, producer не може додати нових даних в чергу


